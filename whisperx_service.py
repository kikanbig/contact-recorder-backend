#!/usr/bin/env python3
"""
–°–≤–µ—Ä—Ö–±—ã—Å—Ç—Ä—ã–π —Å–µ—Ä–≤–∏—Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —á–µ—Ä–µ–∑ WhisperX —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π —Å–ø–∏–∫–µ—Ä–æ–≤
–†–∞–∑–¥–µ–ª—è–µ—Ç –≥–æ–ª–æ—Å–∞ –ø–æ–∫—É–ø–∞—Ç–µ–ª—è –∏ –∫–ª–∏–µ–Ω—Ç–∞, —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ 70x
"""

import sys
import os
import json
import tempfile
import warnings
from pathlib import Path

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

try:
    import whisperx
    import torch
except ImportError as e:
    print(json.dumps({
        'success': False,
        'error': f'–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ WhisperX: {str(e)}'
    }, ensure_ascii=False))
    sys.exit(1)

def format_dialogue(segments, speakers_info):
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –¥–∏–∞–ª–æ–≥ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤
    
    Args:
        segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–ø–∏–∫–µ—Ä–∞—Ö
        speakers_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ø–∏–∫–µ—Ä–∞—Ö
    
    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥
    """
    if not segments or not speakers_info:
        return ""
    
    dialogue_lines = []
    current_speaker = None
    current_text = ""
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª–∏ —Å–ø–∏–∫–µ—Ä–æ–≤
    seller_id = speakers_info.get("seller")
    client_id = speakers_info.get("client")
    
    for segment in segments:
        speaker = segment.get("speaker")
        text = segment.get("text", "").strip()
        
        if not text:
            continue
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª—å —Å–ø–∏–∫–µ—Ä–∞
        if speaker == seller_id:
            speaker_role = "–ü—Ä–æ–¥–∞–≤–µ—Ü"
        elif speaker == client_id:
            speaker_role = "–ö–ª–∏–µ–Ω—Ç"
        elif speaker:
            speaker_role = f"–°–ø–∏–∫–µ—Ä {speaker}"
        else:
            speaker_role = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"
        
        # –ï—Å–ª–∏ —Å–ø–∏–∫–µ—Ä —Å–º–µ–Ω–∏–ª—Å—è, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Ä–µ–ø–ª–∏–∫—É
        if current_speaker and current_speaker != speaker_role and current_text:
            dialogue_lines.append(f"{current_speaker}: {current_text.strip()}")
            current_text = ""
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
        current_speaker = speaker_role
        current_text += " " + text
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–µ–ø–ª–∏–∫—É
    if current_speaker and current_text:
        dialogue_lines.append(f"{current_speaker}: {current_text.strip()}")
    
    return "\n\n".join(dialogue_lines)

def transcribe_with_speaker_diarization(audio_data, language='ru', model_size='small', hf_token=None):
    """
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ WhisperX
    
    Args:
        audio_data: –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
        language: –Ø–∑—ã–∫ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'ru')
        model_size: –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ ('tiny', 'base', 'small', 'medium', 'large')
        hf_token: HuggingFace —Ç–æ–∫–µ–Ω –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        dict: {
            'success': bool,
            'text': str,
            'speakers': dict,
            'segments': list,
            'error': str
        }
    """
    try:
        print(f"üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º WhisperX –º–æ–¥–µ–ª—å: {model_size}", file=sys.stderr)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU/GPU)
        device = "cuda" if torch.cuda.is_available() else "cpu"
        compute_type = "float16" if device == "cuda" else "int8"
        
        print(f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}, —Ç–∏–ø –≤—ã—á–∏—Å–ª–µ–Ω–∏–π: {compute_type}", file=sys.stderr)
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ
        with tempfile.NamedTemporaryFile(suffix='.m4a', delete=False) as temp_file:
            temp_file.write(audio_data)
            temp_path = temp_file.name
        
        try:
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å WhisperX
            model = whisperx.load_model(
                model_size, 
                device=device, 
                compute_type=compute_type,
                language=language
            )
            
            print(f"‚úÖ WhisperX –º–æ–¥–µ–ª—å {model_size} –∑–∞–≥—Ä—É–∂–µ–Ω–∞", file=sys.stderr)
            
            # 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å –±–∞—Ç—á–∏–Ω–≥–æ–º (–æ—Å–Ω–æ–≤–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ)
            print(f"üéµ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å –±–∞—Ç—á–∏–Ω–≥–æ–º...", file=sys.stderr)
            
            audio = whisperx.load_audio(temp_path)
            result = model.transcribe(
                audio, 
                batch_size=16,  # –ë–∞—Ç—á–∏–Ω–≥ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –¥–æ 70x
                language=language
            )
            
            print(f"‚ö° –ë–∞–∑–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞", file=sys.stderr)
            
            # 3. –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å–ª–æ–≤ (word-level alignment)
            print(f"üéØ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å–ª–æ–≤...", file=sys.stderr)
            
            model_a, metadata = whisperx.load_align_model(
                language_code=language, 
                device=device
            )
            
            result = whisperx.align(
                result["segments"], 
                model_a, 
                metadata, 
                audio, 
                device, 
                return_char_alignments=False
            )
            
            print(f"‚úÖ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ", file=sys.stderr)
            
            # 4. –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ (—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤)
            speakers_info = {}
            segments_with_speakers = result["segments"]
            
            try:
                if hf_token:
                    print(f"üë• –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ —Å HF —Ç–æ–∫–µ–Ω–æ–º...", file=sys.stderr)
                    
                    diarize_model = whisperx.DiarizationPipeline(
                        use_auth_token=hf_token, 
                        device=device
                    )
                    
                    diarize_segments = diarize_model(audio)
                    result = whisperx.assign_word_speakers(diarize_segments, result)
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤
                    speakers = set()
                    for segment in result["segments"]:
                        if "speaker" in segment:
                            speakers.add(segment["speaker"])
                    
                    speakers_list = sorted(list(speakers))
                    
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º: –ø–µ—Ä–≤—ã–π —Å–ø–∏–∫–µ—Ä = –ø—Ä–æ–¥–∞–≤–µ—Ü, –≤—Ç–æ—Ä–æ–π = –∫–ª–∏–µ–Ω—Ç
                    if len(speakers_list) >= 2:
                        speakers_info = {
                            "seller": speakers_list[0],
                            "client": speakers_list[1],
                            "total_speakers": len(speakers_list),
                            "all_speakers": speakers_list
                        }
                    elif len(speakers_list) == 1:
                        speakers_info = {
                            "seller": speakers_list[0],
                            "client": None,
                            "total_speakers": 1,
                            "all_speakers": speakers_list,
                            "note": "–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–ø–∏–∫–µ—Ä"
                        }
                    
                    segments_with_speakers = result["segments"]
                    print(f"‚úÖ –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(speakers_list)} —Å–ø–∏–∫–µ—Ä–æ–≤", file=sys.stderr)
                    
                else:
                    print(f"‚ö†Ô∏è –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—â–µ–Ω–∞: –Ω–µ—Ç HF —Ç–æ–∫–µ–Ω–∞", file=sys.stderr)
                    speakers_info = {
                        "note": "–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –±–µ–∑ HuggingFace —Ç–æ–∫–µ–Ω–∞"
                    }
                    
            except Exception as diarize_error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏: {str(diarize_error)}", file=sys.stderr)
                speakers_info = {
                    "error": f"–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {str(diarize_error)}"
                }
            
            # 5. –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            full_text = ""
            seller_text = ""
            client_text = ""
            
            for segment in segments_with_speakers:
                text = segment.get("text", "").strip()
                full_text += text + " "
                
                speaker = segment.get("speaker")
                if speaker == speakers_info.get("seller"):
                    seller_text += text + " "
                elif speaker == speakers_info.get("client"):
                    client_text += text + " "
            
            full_text = full_text.strip()
            seller_text = seller_text.strip()
            client_text = client_text.strip()
            
            # 6. –°–æ–∑–¥–∞—ë–º –¥–∏–∞–ª–æ–≥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–ü—Ä–æ–¥–∞–≤–µ—Ü: ... –ö–ª–∏–µ–Ω—Ç: ..."
            dialogue_text = format_dialogue(segments_with_speakers, speakers_info)
            
            print(f"‚úÖ WhisperX —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤", file=sys.stderr)
            print(f"üë§ –ü—Ä–æ–¥–∞–≤–µ—Ü: {len(seller_text)} —Å–∏–º–≤–æ–ª–æ–≤", file=sys.stderr)
            print(f"üõí –ö–ª–∏–µ–Ω—Ç: {len(client_text)} —Å–∏–º–≤–æ–ª–æ–≤", file=sys.stderr)
            print(f"üí¨ –î–∏–∞–ª–æ–≥: {len(dialogue_text)} —Å–∏–º–≤–æ–ª–æ–≤", file=sys.stderr)
            
            return {
                'success': True,
                'text': full_text,
                'dialogue': dialogue_text,
                'seller_text': seller_text,
                'client_text': client_text,
                'speakers': speakers_info,
                'segments': segments_with_speakers,
                'language': language,
                'model_used': f'whisperx-{model_size}',
                'device': device,
                'error': None
            }
        
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.unlink(temp_path)
            except:
                pass
                
    except Exception as e:
        error_message = str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞ WhisperX —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {error_message}", file=sys.stderr)
        return {
            'success': False,
            'text': '',
            'dialogue': '',
            'seller_text': '',
            'client_text': '',
            'speakers': {},
            'segments': [],
            'error': error_message
        }

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ –∏–∑ Node.js
    –û–∂–∏–¥–∞–µ—Ç –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    """
    if len(sys.argv) < 2:
        print(json.dumps({
            'success': False,
            'error': '–ù–µ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É'
        }, ensure_ascii=False))
        sys.exit(1)
    
    audio_file_path = sys.argv[1]
    language = sys.argv[2] if len(sys.argv) > 2 else 'ru'
    model_size = sys.argv[3] if len(sys.argv) > 3 else 'small'
    hf_token = sys.argv[4] if len(sys.argv) > 4 else None
    
    try:
        print(f"üìÇ –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª: {audio_file_path}", file=sys.stderr)
        
        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
        with open(audio_file_path, 'rb') as f:
            audio_data = f.read()
        
        print(f"üì¶ –†–∞–∑–º–µ—Ä –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞: {len(audio_data)} –±–∞–π—Ç", file=sys.stderr)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å WhisperX –∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π
        result = transcribe_with_speaker_diarization(audio_data, language, model_size, hf_token)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Node.js (—Ç–æ–ª—å–∫–æ –≤ stdout)
        print(json.dumps(result, ensure_ascii=False))
        
    except Exception as e:
        print(json.dumps({
            'success': False,
            'error': f'–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {str(e)}'
        }, ensure_ascii=False))
        sys.exit(1)

if __name__ == '__main__':
    main() 